{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Œ 1ë“±íŒ€ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python black formatter ì ìš©\n",
    "%load_ext nb_black\n",
    "%load_ext lab_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° í”„ë ˆì„ì˜ ë°ì´í„°íƒ€ì… ì§€ì •\n",
    "dtype = {\"userID\": \"int16\", \"answerCode\": \"int8\", \"KnowledgeTag\": \"int16\"}\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ë§ì¶°ì£¼ì„¸ìš”!\n",
    "DATA_PATH = \"/opt/ml/input/data/FE_total_data.csv\"\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, dtype=dtype, parse_dates=[\"Timestamp\"])\n",
    "df = df.sort_values(by=[\"userID\", \"Timestamp\"]).reset_index(drop=True)\n",
    "\n",
    "train = pd.read_csv(DATA_PATH, dtype=dtype, parse_dates=[\"Timestamp\"])\n",
    "train = train.sort_values(by=[\"userID\", \"Timestamp\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"problem_number\"] = df[\"assessmentItemID\"].apply(lambda x: int(x[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_t = df.groupby([\"testId\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_t.columns = [\"test_mean\", \"test_sum\"]\n",
    "correct_k = df.groupby([\"KnowledgeTag\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_k.columns = [\"tag_mean\", \"tag_sum\"]\n",
    "correct_a = df.groupby([\"assessmentItemID\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_a.columns = [\"ass_mean\", \"ass_sum\"]\n",
    "correct_p = df.groupby([\"problem_number\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "correct_p.columns = [\"prb_mean\", \"prb_sum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_last_problem(df):\n",
    "    new = []\n",
    "    pre = df[\"testId\"][0]\n",
    "    for idx in df[\"testId\"]:\n",
    "        if pre != idx:\n",
    "            new[-1] = -1\n",
    "            pre = idx\n",
    "        new.append(0)\n",
    "    df[\"last_problem\"] = new\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_previous_ordered(row):\n",
    "    q_num = row.problem_number\n",
    "    q_num_prev = row.q_num_prev\n",
    "    delta = row.delta\n",
    "    delta_thres = 1  # hour\n",
    "\n",
    "    if pd.isnull(delta) or delta > pd.Timedelta(hours=1):\n",
    "        return -1\n",
    "    elif q_num == q_num_prev + 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_previous_decreasing(row):\n",
    "    q_num = row.problem_number\n",
    "    q_num_prev = row.q_num_prev\n",
    "    delta = row.delta\n",
    "    delta_thres = 1  # hour\n",
    "\n",
    "    if pd.isnull(delta) or delta > pd.Timedelta(hours=1):\n",
    "        return -1\n",
    "    elif q_num < q_num_prev:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_probably_easy(row):\n",
    "    delta = row.delta\n",
    "    delta_thres = 1  # hour\n",
    "\n",
    "    is_prev_ord = row.is_previous_ordered\n",
    "    is_prev_dec = row.is_previous_decreasing\n",
    "    is_prev_ord_shift = row.is_prev_ord_shift\n",
    "    is_prev_dec_shift = row.is_prev_dec_shift\n",
    "\n",
    "    case = (is_prev_ord_shift, is_prev_dec_shift, is_prev_ord, is_prev_dec)\n",
    "\n",
    "    probably_easy_l = [\n",
    "        (np.nan, np.nan, -1, -1),\n",
    "        (-1, -1, 1, 0),\n",
    "        (1, 0, 1, 0),\n",
    "        (1, 0, 0, 0),\n",
    "    ]\n",
    "\n",
    "    if pd.isnull(delta) or delta > pd.Timedelta(hours=1):\n",
    "        return -1\n",
    "    elif case in probably_easy_l:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‚œì´ë„ ì„¤ì •ì„ ìœ„í•œ ELO ì‚¬ìš©\n",
    "def ELO_function(df):\n",
    "    def get_new_theta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return theta + learning_rate_theta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def get_new_beta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return beta - learning_rate_beta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def learning_rate_theta(nb_answers):\n",
    "        return max(0.3 / (1 + 0.01 * nb_answers), 0.04)\n",
    "\n",
    "    def learning_rate_beta(nb_answers):\n",
    "        return 1 / (1 + 0.05 * nb_answers)\n",
    "\n",
    "    def probability_of_good_answer(theta, beta, left_asymptote):\n",
    "        return left_asymptote + (1 - left_asymptote) * sigmoid(theta - beta)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def estimate_parameters(answers_df, granularity_feature_name=\"assessmentItemID\"):\n",
    "        item_parameters = {\n",
    "            granularity_feature_value: {\"beta\": 0, \"nb_answers\": 0}\n",
    "            for granularity_feature_value in np.unique(\n",
    "                answers_df[granularity_feature_name]\n",
    "            )\n",
    "        }\n",
    "        student_parameters = {\n",
    "            student_id: {\"theta\": 0, \"nb_answers\": 0}\n",
    "            for student_id in np.unique(answers_df.userID)\n",
    "        }\n",
    "\n",
    "        print(\"Parameter estimation is starting...\")\n",
    "\n",
    "        for student_id, item_id, left_asymptote, answered_correctly in tqdm(\n",
    "            zip(\n",
    "                answers_df.userID.values,\n",
    "                answers_df[granularity_feature_name].values,\n",
    "                answers_df.left_asymptote.values,\n",
    "                answers_df.answerCode.values,\n",
    "            )\n",
    "        ):\n",
    "            theta = student_parameters[student_id][\"theta\"]\n",
    "            beta = item_parameters[item_id][\"beta\"]\n",
    "\n",
    "            item_parameters[item_id][\"beta\"] = get_new_beta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                item_parameters[item_id][\"nb_answers\"],\n",
    "            )\n",
    "            student_parameters[student_id][\"theta\"] = get_new_theta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                student_parameters[student_id][\"nb_answers\"],\n",
    "            )\n",
    "\n",
    "            item_parameters[item_id][\"nb_answers\"] += 1\n",
    "            student_parameters[student_id][\"nb_answers\"] += 1\n",
    "\n",
    "        print(f\"Theta & beta estimations on {granularity_feature_name} are completed.\")\n",
    "        return student_parameters, item_parameters\n",
    "\n",
    "    def gou_func(theta, beta):\n",
    "        return 1 / (1 + np.exp(-(theta - beta)))\n",
    "\n",
    "    df[\"left_asymptote\"] = 0\n",
    "\n",
    "    print(f\"Dataset of shape {df.shape}\")\n",
    "    print(f\"Columns are {list(df.columns)}\")\n",
    "\n",
    "    student_parameters, item_parameters = estimate_parameters(df)\n",
    "\n",
    "    prob = [\n",
    "        gou_func(student_parameters[student][\"theta\"], item_parameters[item][\"beta\"])\n",
    "        for student, item in zip(df.userID.values, df.assessmentItemID.values)\n",
    "    ]\n",
    "\n",
    "    df[\"elo_prob\"] = prob\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    print(\"-\" * 20, \"Feature Engineering Start\", \"-\" * 20)\n",
    "    start_time = time.time()\n",
    "    # ìœ ì €ë³„ ì‹œí€€ìŠ¤ë¥¼ ê³ ë ¤í•˜ê¸° ìœ„í•´ ì•„ë˜ì™€ ê°™ì´ ì •ë ¬\n",
    "    df.sort_values(by=[\"userID\", \"Timestamp\"], inplace=True)\n",
    "    df = add_last_problem(df)\n",
    "    # elo ì¶”ê°€\n",
    "    df = ELO_function(df)\n",
    "\n",
    "    df[\"hour\"] = df[\"Timestamp\"].dt.hour\n",
    "    df[\"dow\"] = df[\"Timestamp\"].dt.dayofweek\n",
    "\n",
    "    # í‘¸ëŠ” ì‹œê°„\n",
    "    diff = (\n",
    "        df.loc[:, [\"userID\", \"Timestamp\"]]\n",
    "        .groupby(\"userID\")\n",
    "        .diff()\n",
    "        .fillna(pd.Timedelta(seconds=0))\n",
    "    )\n",
    "    diff = diff.fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff[\"Timestamp\"].apply(lambda x: x.total_seconds())\n",
    "    df[\"elapsed\"] = diff\n",
    "    df[\"elapsed\"] = df[\"elapsed\"].apply(lambda x: x if x < 650 and x >= 0 else 0)\n",
    "\n",
    "    df[\"grade\"] = df[\"testId\"].apply(lambda x: int(x[1:4]) // 10)\n",
    "    df[\"mid\"] = df[\"testId\"].apply(lambda x: int(x[-3:]))\n",
    "    df[\"problem_number\"] = df[\"assessmentItemID\"].apply(lambda x: int(x[-3:]))\n",
    "\n",
    "    correct_h = df.groupby([\"hour\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "    correct_h.columns = [\"hour_mean\", \"hour_sum\"]\n",
    "    correct_d = df.groupby([\"dow\"])[\"answerCode\"].agg([\"mean\", \"sum\"])\n",
    "    correct_d.columns = [\"dow_mean\", \"dow_sum\"]\n",
    "\n",
    "    df = pd.merge(df, correct_t, on=[\"testId\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_k, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_a, on=[\"assessmentItemID\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_p, on=[\"problem_number\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_h, on=[\"hour\"], how=\"left\")\n",
    "    df = pd.merge(df, correct_d, on=[\"dow\"], how=\"left\")\n",
    "\n",
    "    o_df = df[df[\"answerCode\"] == 1]\n",
    "    x_df = df[df[\"answerCode\"] == 0]\n",
    "\n",
    "    elp_k = df.groupby([\"KnowledgeTag\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    elp_k.columns = [\"KnowledgeTag\", \"tag_elp\"]\n",
    "    elp_k_o = o_df.groupby([\"KnowledgeTag\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    elp_k_o.columns = [\"KnowledgeTag\", \"tag_elp_o\"]\n",
    "    elp_k_x = x_df.groupby([\"KnowledgeTag\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    elp_k_x.columns = [\"KnowledgeTag\", \"tag_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, elp_k, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "    df = pd.merge(df, elp_k_o, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "    df = pd.merge(df, elp_k_x, on=[\"KnowledgeTag\"], how=\"left\")\n",
    "\n",
    "    ass_k = df.groupby([\"assessmentItemID\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    ass_k.columns = [\"assessmentItemID\", \"ass_elp\"]\n",
    "    ass_k_o = o_df.groupby([\"assessmentItemID\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    ass_k_o.columns = [\"assessmentItemID\", \"ass_elp_o\"]\n",
    "    ass_k_x = x_df.groupby([\"assessmentItemID\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    ass_k_x.columns = [\"assessmentItemID\", \"ass_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, ass_k, on=[\"assessmentItemID\"], how=\"left\")\n",
    "    df = pd.merge(df, ass_k_o, on=[\"assessmentItemID\"], how=\"left\")\n",
    "    df = pd.merge(df, ass_k_x, on=[\"assessmentItemID\"], how=\"left\")\n",
    "\n",
    "    prb_k = df.groupby([\"problem_number\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    prb_k.columns = [\"problem_number\", \"prb_elp\"]\n",
    "    prb_k_o = o_df.groupby([\"problem_number\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    prb_k_o.columns = [\"problem_number\", \"prb_elp_o\"]\n",
    "    prb_k_x = x_df.groupby([\"problem_number\"])[\"elapsed\"].agg(\"mean\").reset_index()\n",
    "    prb_k_x.columns = [\"problem_number\", \"prb_elp_x\"]\n",
    "\n",
    "    df = pd.merge(df, prb_k, on=[\"problem_number\"], how=\"left\")\n",
    "    df = pd.merge(df, prb_k_o, on=[\"problem_number\"], how=\"left\")\n",
    "    df = pd.merge(df, prb_k_x, on=[\"problem_number\"], how=\"left\")\n",
    "\n",
    "    df[\"user_correct_answer\"] = (\n",
    "        df.groupby(\"userID\")[\"answerCode\"]\n",
    "        .transform(lambda x: x.cumsum().shift(1))\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df[\"user_total_answer\"] = df.groupby(\"userID\")[\"answerCode\"].cumcount()\n",
    "    df[\"user_acc\"] = (df[\"user_correct_answer\"] / df[\"user_total_answer\"]).fillna(0)\n",
    "    df[\"Grade_o\"] = (\n",
    "        df.groupby([\"userID\", \"grade\"])[\"answerCode\"]\n",
    "        .transform(lambda x: x.cumsum().shift(1))\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df[\"GradeCount\"] = df.groupby([\"userID\", \"grade\"]).cumcount()\n",
    "    df[\"GradeAcc\"] = (df[\"Grade_o\"] / df[\"GradeCount\"]).fillna(0)\n",
    "    df[\"GradeElp\"] = (\n",
    "        df.groupby([\"userID\", \"grade\"])[\"elapsed\"]\n",
    "        .transform(lambda x: x.cumsum())\n",
    "        .fillna(0)\n",
    "    )\n",
    "    df[\"GradeMElp\"] = df[\"GradeElp\"] / [\n",
    "        v if v != 0 else 1 for v in df[\"GradeCount\"].values\n",
    "    ]\n",
    "\n",
    "    f = lambda x: len(set(x))\n",
    "    test = df.groupby([\"testId\"]).agg({\"problem_number\": \"max\", \"KnowledgeTag\": f})\n",
    "    test.reset_index(inplace=True)\n",
    "\n",
    "    test.columns = [\"testId\", \"problem_count\", \"tag_count\"]\n",
    "\n",
    "    df = pd.merge(df, test, on=\"testId\", how=\"left\")\n",
    "\n",
    "    gdf = df[[\"userID\", \"testId\", \"problem_number\", \"grade\", \"Timestamp\"]].sort_values(\n",
    "        by=[\"userID\", \"grade\", \"Timestamp\"]\n",
    "    )\n",
    "    gdf[\"buserID\"] = gdf[\"userID\"] != gdf[\"userID\"].shift(1)\n",
    "    gdf[\"bgrade\"] = gdf[\"grade\"] != gdf[\"grade\"].shift(1)\n",
    "    gdf[\"first\"] = gdf[[\"buserID\", \"bgrade\"]].any(axis=1).apply(lambda x: 1 - int(x))\n",
    "    gdf[\"RepeatedTime\"] = gdf[\"Timestamp\"].diff().fillna(pd.Timedelta(seconds=0))\n",
    "    gdf[\"RepeatedTime\"] = (\n",
    "        gdf[\"RepeatedTime\"].apply(lambda x: x.total_seconds()) * gdf[\"first\"]\n",
    "    )\n",
    "    df[\"RepeatedTime\"] = gdf[\"RepeatedTime\"].apply(lambda x: math.log(x + 1))\n",
    "\n",
    "    df[\"prior_KnowledgeTag_frequency\"] = df.groupby(\n",
    "        [\"userID\", \"KnowledgeTag\"]\n",
    "    ).cumcount()\n",
    "\n",
    "    df[\"problem_position\"] = df[\"problem_number\"] / df[\"problem_count\"]\n",
    "    df[\"solve_order\"] = df.groupby([\"userID\", \"testId\"]).cumcount()\n",
    "    df[\"solve_order\"] = (\n",
    "        df[\"solve_order\"]\n",
    "        - df[\"problem_count\"] * (df[\"solve_order\"] > df[\"problem_count\"]).apply(int)\n",
    "        + 1\n",
    "    )\n",
    "    df[\"retest\"] = (df[\"solve_order\"] > df[\"problem_count\"]).apply(int)\n",
    "    T = df[\"solve_order\"] != df[\"problem_number\"]\n",
    "    TT = T.shift(1)\n",
    "    TT[0] = False\n",
    "    df[\"solved_disorder\"] = (TT.apply(lambda x: not x) & T).apply(int)\n",
    "\n",
    "    df[\"testId\"] = df[\"testId\"].apply(lambda x: int(x[1:4] + x[-3]))\n",
    "\n",
    "    print(\"-\" * 20, \"Feature Engineering End\", \"-\" * 20)\n",
    "    print(f\"Feature Engineeringì— ê±¸ë¦° ì‹œê°„ : {time.time() - start_time}s\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = feature_engineering(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null ê°’ ë¶„í¬ ìš°ì„  fillnaë¡œ ì²˜ë¦¬\n",
    "train = train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"/opt/ml/input/data/train_after.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
